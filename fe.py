import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from tavily import TavilyClient
from openai import OpenAI
import plotly.graph_objects as go
import json
import concurrent.futures
import time
import random
import requests
import feedparser
import re

# --- HARDCODED KEYS (Hidden from UI) ---
TAVILY_API_KEY = "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"
ALPHA_VANTAGE_KEY = "8G1QKAWN221XEZR8"

# --- PAGE SETUP ---
st.set_page_config(
    page_title="MAS è”åˆç ”æŠ¥ç»ˆç«¯ v3.5",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS STYLING ---
st.markdown("""
<style>
    .stApp { background-color: #ffffff; color: #1f2937; }
    .stTextInput > div > div > input { background-color: #f3f4f6; color: #1f2937; }
    .stChatMessage .stChatMessageAvatar { background-color: #e5e7eb; border-radius: 50%; }
    div[data-testid="metric-container"] { background-color: #f9fafb; border: 1px solid #e5e7eb; padding: 10px; border-radius: 8px; }
    
    .thinking-box {
        font-size: 0.85em;
        color: #6b7280;
        border-left: 3px solid #e5e7eb;
        padding-left: 10px;
        margin-bottom: 10px;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# --- SESSION STATE INITIALIZATION ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "é¦–å¸­ç ”ç©¶å‘˜å°±ä½ã€‚è¯·ä¸‹è¾¾è°ƒç ”æŒ‡ä»¤ï¼ˆå¦‚ï¼šåˆ†æ æ˜“ç‚¹å¤©ä¸‹ï¼‰ã€‚", "avatar": "ğŸ‘¨â€ğŸ”¬"}]
if "process_status" not in st.session_state:
    st.session_state.process_status = "IDLE"
if "ticker" not in st.session_state:
    st.session_state.ticker = None
if "market_data" not in st.session_state:
    st.session_state.market_data = None
if "raw_news" not in st.session_state:
    st.session_state.raw_news = {}
if "retry_count" not in st.session_state:
    st.session_state.retry_count = 0
if "last_rework_field" not in st.session_state:
    st.session_state.last_rework_field = None

# --- SIDEBAR ---
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    st.subheader("ğŸ”‘ é‰´æƒè®¾ç½®")
    
    default_sf_key = st.secrets.get("SILICON_FLOW_KEY", "")
    silicon_flow_key = st.text_input("SiliconFlow Key", value=default_sf_key, type="password", help="è¯·è¾“å…¥æ‚¨çš„ç¡…åŸºæµåŠ¨ API Key")

    if not silicon_flow_key:
        st.warning("âš ï¸ è¯·è¾“å…¥ SiliconFlow API Key ä»¥å¯åŠ¨å¤§æ¨¡å‹")
    else:
        st.success("âœ… ç³»ç»Ÿå·²å°±ç»ª")
    
    st.divider()
    if st.button("ğŸ”„ é‡ç½®ç³»ç»ŸçŠ¶æ€"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# --- UTILS ---

def extract_json_from_markdown(text):
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(0))
            except:
                pass
    return None

def get_llm_client():
    if not silicon_flow_key: return None
    return OpenAI(api_key=silicon_flow_key, base_url="https://api.siliconflow.cn/v1")

def get_tavily_client():
    return TavilyClient(api_key=TAVILY_API_KEY)

def calculate_technical_indicators(df):
    if df.empty: return df
    exp12 = df['Close'].ewm(span=12, adjust=False).mean()
    exp26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp12 - exp26
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['Signal_Line']
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

def fetch_from_alphavantage(ticker):
    try:
        url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={ALPHA_VANTAGE_KEY}&outputsize=compact"
        r = requests.get(url, timeout=10)
        data = r.json()
        if "Time Series (Daily)" not in data: return None
        
        df = pd.DataFrame.from_dict(data["Time Series (Daily)"], orient='index')
        df = df.rename(columns={"4. close": "Close", "1. open": "Open", "2. high": "High", "3. low": "Low"})
        df = df.astype(float).sort_index()
        df = calculate_technical_indicators(df)
        
        return {
            "status": "ONLINE (AV Backup)",
            "symbol": ticker.upper(),
            "name": ticker,
            "price": df['Close'].iloc[-1],
            "change_pct": 0.0,
            "pe": "N/A",
            "cap": "N/A",
            "history_df": df,
            "last_macd": {"hist": df['MACD_Hist'].iloc[-1]},
            "last_rsi": df['RSI'].iloc[-1]
        }
    except:
        return None

def fetch_from_yfinance(ticker):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="6mo")
        if hist.empty: return None
        hist = calculate_technical_indicators(hist)
        info = stock.info
        return {
            "status": "ONLINE (YF)",
            "symbol": ticker.upper(),
            "name": info.get('longName', ticker),
            "price": info.get('currentPrice', hist['Close'].iloc[-1]),
            "change_pct": ((hist['Close'].iloc[-1] - hist['Close'].iloc[-2])/hist['Close'].iloc[-2])*100,
            "pe": info.get('trailingPE', 'N/A'),
            "cap": info.get('marketCap', 'N/A'),
            "history_df": hist,
            "last_macd": {"hist": hist['MACD_Hist'].iloc[-1]},
            "last_rsi": hist['RSI'].iloc[-1]
        }
    except:
        return None

def fetch_market_data(ticker):
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_yf = executor.submit(fetch_from_yfinance, ticker)
        future_av = executor.submit(fetch_from_alphavantage, ticker)
        
        yf_data = future_yf.result()
        if yf_data: return yf_data
        
        av_data = future_av.result()
        if av_data: return av_data
        
    return {"status": "OFFLINE", "error": "Market data unavailable from both YF and AV"}

def search_web(query, topic="general"):
    try:
        tavily = get_tavily_client()
        res = tavily.search(query=query, topic=topic, max_results=5)
        return [f"- {r['title']}: {r['content'][:300]}" for r in res['results']]
    except Exception as e:
        return [f"Search Error: {str(e)}"]

def call_agent(agent_name, model_id, system_prompt, user_prompt, thinking_needed=False):
    client = get_llm_client()
    if not client: return "API Key Missing", ""
    
    final_sys_prompt = system_prompt
    
    # --- æ ¼å¼ä¸è¯­è¨€å®ªæ³• (Format & Language Constitution) ---
    final_sys_prompt += """
    
    ã€é‡è¦è¾“å‡ºæŒ‡ä»¤ã€‘
    1. è¯­è¨€ï¼šå¿…é¡»å…¨ç§°ä½¿ç”¨ç®€ä½“ä¸­æ–‡ (Simplified Chinese) å›å¤ã€‚ä¸¥ç¦ä½¿ç”¨è‹±æ–‡ï¼ˆé™¤éæ˜¯ä¸“æœ‰åè¯ä»£ç ï¼‰ã€‚
    2. æ ¼å¼ï¼šç¦æ­¢ä½¿ç”¨ä¸€çº§(#)æˆ–äºŒçº§(##)å¤§æ ‡é¢˜ã€‚æœ€å¤§åªèƒ½ä½¿ç”¨ä¸‰çº§(###)æ ‡é¢˜ã€‚å»ºè®®å¤šç”¨**åŠ ç²—**æ¥å¼ºè°ƒã€‚
    3. å†…å®¹ï¼šä¸¥ç¦é‡å¤è¾“å‡ºç›¸åŒçš„æ®µè½æˆ–æ ‡é¢˜ã€‚ä¿æŒå›ç­”ç²¾ç‚¼ã€ç´§å‡‘ã€‚
    """

    if thinking_needed:
        final_sys_prompt += "\nIMPORTANT: You MUST first output your internal thinking process wrapped in <thinking>...</thinking> tags, then output your final response."

    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": final_sys_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2048
        )
        content = response.choices[0].message.content
        
        thinking = ""
        if "<thinking>" in content:
            match = re.search(r"<thinking>(.*?)</thinking>", content, re.DOTALL)
            if match:
                thinking = match.group(1).strip()
                content = re.sub(r"<thinking>.*?</thinking>", "", content, flags=re.DOTALL).strip()
        
        return content, thinking
    except Exception as e:
        return f"âš ï¸ {agent_name} Error: {str(e)}", ""

# --- MODEL MAP ---
SPECIFIC_MODELS = {
    "DEEPSEEK": "deepseek-ai/DeepSeek-V3", 
    "KIMI": "moonshotai/Kimi-K2-Thinking",
    "MINIMAX": "MiniMaxAI/MiniMax-M2",
    "QWEN": "Qwen/Qwen2.5-72B-Instruct"
}

# --- MAIN UI LOGIC ---

st.title("ğŸ¦ MAS è”åˆç ”æŠ¥ç»ˆç«¯ v3.6 (Chinese Fixed)")
st.caption(f"æ··åˆæ¨¡å‹å¼•æ“: Qwen (è·¯ç”±) | MiniMax (æƒ…æŠ¥) | DeepSeek (åˆ†æ) | Kimi (é¦–å¸­ç ”ç©¶)")

# 1. Chat History Rendering
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.markdown(msg["content"])
        if msg.get("thinking"):
            with st.expander("ğŸ§  æ€è€ƒè¿‡ç¨‹ (Thinking Chain)", expanded=False):
                st.markdown(f"_{msg['thinking']}_")

# 2. Input Handler
if user_input := st.chat_input("è¯·è¾“å…¥æ ‡çš„..."):
    if not silicon_flow_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥ SiliconFlow API Key")
        st.stop()

    st.session_state.ticker = None
    st.session_state.market_data = None
    st.session_state.raw_news = {}
    st.session_state.retry_count = 0
    st.session_state.final_report = None
    st.session_state.last_rework_field = None
    
    st.session_state.messages.append({"role": "user", "content": user_input, "avatar": "ğŸ‘¤"})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)

    # --- STEP 1: SMART ROUTER (Verification Added) ---
    with st.chat_message("assistant", avatar="ğŸ‘©â€ğŸ’¼"):
        st.write("ğŸ” è‘£ç§˜æ­£åœ¨æ ¸å®ä»£ç ...")
        
        # 1. Double Search (English + Chinese)
        # English search is good for tickers, Chinese search ensures we get A-share context
        with concurrent.futures.ThreadPoolExecutor() as executor:
            f_en = executor.submit(search_web, f"{user_input} stock ticker Yahoo Finance", "general")
            f_cn = executor.submit(search_web, f"{user_input} è‚¡ç¥¨ä»£ç ", "general")
            search_res = f_en.result() + f_cn.result()
        
        search_context = "\n".join(search_res)
        
        # 2. Extract
        router_prompt = f"""
        ç”¨æˆ·æƒ³è¦åˆ†æ: "{user_input}"
        
        æœç´¢ç»“æœ:
        {search_context}
        
        è¯·æå–Yahoo Finance Tickerã€‚
        è§„åˆ™ï¼š
        1. Aè‚¡å¿…é¡»æ˜¯ 6 ä½æ•°å­— + .SS (ä¸Šæµ·) æˆ– .SZ (æ·±åœ³)ã€‚ä¾‹å¦‚ 301171 -> 301171.SZ
        2. æ¸¯è‚¡æ˜¯ 4 ä½æ•°å­— + .HK
        3. ç¾è‚¡æ˜¯å­—æ¯
        4. åŠ¡å¿…åŒºåˆ†â€œæ˜“ç‚¹å¤©ä¸‹(301171)â€å’Œâ€œä¸­ç§‘æ¶¦å®‡(301175)â€ç­‰ç›¸ä¼¼ä»£ç ï¼Œä¾é æœç´¢ç»“æœä¸­çš„å…¬å¸ååŒ¹é…ã€‚
        
        è¿”å›JSON: {{'ticker': '...', 'company_name_in_search': '...'}}
        """
        
        res, _ = call_agent("Router", SPECIFIC_MODELS["QWEN"], "ä½ æ˜¯è‘£ç§˜ã€‚ç²¾ç¡®æå–ä»£ç ã€‚", router_prompt)
        json_data = extract_json_from_markdown(res)
        
        if json_data and 'ticker' in json_data:
            ticker_candidate = json_data['ticker']
            
            # 3. IDENTITY VERIFICATION (New Step)
            # Fetch real name from YFinance to double check
            try:
                real_info = yf.Ticker(ticker_candidate).info
                real_name = real_info.get('longName', '') or real_info.get('shortName', '')
                
                if real_name:
                    # Let Qwen confirm if "real_name" matches "user_input"
                    verify_prompt = f"""
                    ç”¨æˆ·è¾“å…¥: "{user_input}"
                    æå–ä»£ç : "{ticker_candidate}"
                    è¯¥ä»£ç å¯¹åº”çš„å®˜æ–¹åç§°: "{real_name}"
                    
                    è¯·åˆ¤æ–­å®˜æ–¹åç§°æ˜¯å¦ä¸ç”¨æˆ·è¾“å…¥åŒ¹é…ï¼Ÿ
                    å¦‚æœåŒ¹é…ï¼Œè¿”å› "YES"ã€‚
                    å¦‚æœä¸åŒ¹é…ï¼ˆä¾‹å¦‚ç”¨æˆ·æœæ˜“ç‚¹å¤©ä¸‹ï¼Œä½†ä»£ç å¯¹åº”ä¸­ç§‘æ¶¦å®‡ï¼‰ï¼Œè¿”å› "NO"ã€‚
                    """
                    verify_res, _ = call_agent("Verifier", SPECIFIC_MODELS["QWEN"], "ä½ æ˜¯å®¡æ ¸å‘˜ã€‚", verify_prompt)
                    
                    if "NO" in verify_res:
                        st.error(f"âš ï¸ è­¦å‘Šï¼šä»£ç  {ticker_candidate} å¯¹åº”å…¬å¸ä¸º **{real_name}**ï¼Œä¼¼ä¹ä¸æ‚¨çš„è¾“å…¥ä¸ç¬¦ã€‚è¯·å°è¯•è¾“å…¥æ›´å‡†ç¡®çš„å…¨åã€‚")
                        st.stop()
                    else:
                        st.session_state.ticker = ticker_candidate
                        st.markdown(f"âœ… èº«ä»½æ ¸éªŒé€šè¿‡ï¼š**{real_name} ({ticker_candidate})**")
                        st.session_state.process_status = "ANALYZING"
                        st.rerun()
                else:
                    # Fallback if YF fails to get name (e.g. network issue), trust LLM but warn
                    st.warning(f"âš ï¸ æ— æ³•ä»äº¤æ˜“æ‰€éªŒè¯ä»£ç  {ticker_candidate}ï¼Œå°†å°è¯•å¼ºè¡Œåˆ†æ...")
                    st.session_state.ticker = ticker_candidate
                    st.session_state.process_status = "ANALYZING"
                    st.rerun()
            except Exception as e:
                st.error(f"ä»£ç éªŒè¯å¤±è´¥: {str(e)}")
                st.stop()
                
        else:
            st.error("æ— æ³•è¯†åˆ«æœ‰æ•ˆä»£ç ")
            st.stop()

# 3. Analysis Process
if st.session_state.process_status == "ANALYZING" and st.session_state.ticker:
    
    ticker = st.session_state.ticker
    
    # --- STEP A: FETCH DATA ---
    if not st.session_state.market_data:
        with st.status("ğŸ“¡ æ­£åœ¨è¿›è¡Œå…¨ç½‘æƒ…æŠ¥æœé›†...", expanded=True) as status:
            mkt = fetch_market_data(ticker)
            st.session_state.market_data = mkt
            
            if mkt['status'] == "OFFLINE":
                st.error("è¡Œæƒ…æ•°æ®è·å–å¤±è´¥ (Yahoo & Alpha Vantage å‡ä¸å¯ç”¨)")
            
            queries = {
                "macro": "global macro economy news market trends",
                "meso": f"{ticker} industry competitors market share",
                "micro": f"{ticker} stock news financial reports analysis",
                "pol": "international geopolitics trade war impact"
            }
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {k: executor.submit(search_web, v, "news" if k != "meso" else "general") for k, v in queries.items()}
                for k, f in futures.items():
                    st.session_state.raw_news[k] = f.result()
            
            status.update(label="âœ… åˆå§‹æƒ…æŠ¥å·²å°±ç»ª", state="complete")
    
    # --- STEP B: MEETING ---
    mkt = st.session_state.market_data
    news = st.session_state.raw_news
    opinions = {}
    
    st.divider()
    
    # Dashboard
    if mkt and mkt['status'] != "OFFLINE":
        st.markdown(f"### ğŸ“‰ è¡Œæƒ…çœ‹æ¿: {mkt.get('name', ticker)} ({mkt.get('symbol')})")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ä»·æ ¼", f"{mkt['price']:.2f}", f"{mkt['change_pct']:.2f}%")
        c2.metric("PE", mkt.get('pe', 'N/A'))
        c3.metric("RSI", f"{mkt.get('last_rsi', 0):.1f}")
        c4.metric("MACD", f"{mkt.get('last_macd', {}).get('hist', 0):.3f}")
        
        if 'history_df' in mkt:
            fig = go.Figure(data=[go.Candlestick(x=mkt['history_df'].index,
                            open=mkt['history_df']['Open'], high=mkt['history_df']['High'],
                            low=mkt['history_df']['Low'], close=mkt['history_df']['Close'])])
            fig.update_layout(height=350, template="plotly_white", margin=dict(l=0, r=0, t=10, b=0))
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("âš ï¸ æš‚æ— å®æ—¶è¡Œæƒ…Kçº¿")

    st.subheader(f"ğŸ—£ï¸ æŠ•ç ”ä¼šè®® (ç¬¬ {st.session_state.retry_count + 1} è½®)")
    if st.session_state.retry_count > 0:
        st.info(f"ğŸ’¡ æœ¬æ¬¡ä¼šè®®åŒ…å«äº†é’ˆå¯¹ **{st.session_state.last_rework_field}** é¢†åŸŸçš„è¡¥å……æƒ…æŠ¥ã€‚")
    
    with st.chat_message("assistant", avatar="ğŸŒ"):
        prompt = "ç®€è¿°å®è§‚ç¯å¢ƒã€‚"
        if st.session_state.last_rework_field == "macro": prompt += " (åŸºäºæœ€æ–°è¡¥å……æƒ…æŠ¥)"
        res, _ = call_agent("Macro", SPECIFIC_MODELS["MINIMAX"], "ä½ æ˜¯å®è§‚åˆ†æå¸ˆã€‚", f"{prompt}\næƒ…æŠ¥:{str(news['macro'])}")
        st.markdown(f"**å®è§‚**: {res}")
        opinions['macro'] = res

    with st.chat_message("assistant", avatar="ğŸ­"):
        prompt = f"åˆ†æ {ticker} è¡Œä¸šã€‚"
        if st.session_state.last_rework_field == "meso": prompt += " (åŸºäºæœ€æ–°è¡¥å……æƒ…æŠ¥)"
        res, _ = call_agent("Meso", SPECIFIC_MODELS["MINIMAX"], f"ä½ æ˜¯è¡Œä¸šåˆ†æå¸ˆã€‚", f"{prompt}\næƒ…æŠ¥:{str(news['meso'])}")
        st.markdown(f"**è¡Œä¸š**: {res}")
        opinions['meso'] = res

    with st.chat_message("assistant", avatar="ğŸ”"):
        prompt = f"åˆ†æ {ticker} ä¸ªè‚¡ã€‚"
        if st.session_state.last_rework_field == "micro": prompt += " (åŸºäºæœ€æ–°è¡¥å……æƒ…æŠ¥)"
        res, _ = call_agent("Micro", SPECIFIC_MODELS["MINIMAX"], f"ä½ æ˜¯å…¬å¸ç ”ç©¶å‘˜ã€‚", f"{prompt}\næƒ…æŠ¥:{str(news['micro'])}")
        st.markdown(f"**ä¸ªè‚¡**: {res}")
        opinions['micro'] = res
    
    if mkt and mkt['status'] != "OFFLINE":
        with st.chat_message("assistant", avatar="ğŸ’¹"):
            quant_ctx = f"Price:{mkt['price']}, PE:{mkt['pe']}, RSI:{mkt.get('last_rsi')}"
            res, _ = call_agent("Finance", SPECIFIC_MODELS["DEEPSEEK"], "ä½ æ˜¯è´¢åŠ¡ä¸“å®¶ã€‚è¯·åˆ†æä¼°å€¼ä¸æŠ€æœ¯é¢ã€‚", quant_ctx)
            st.markdown(f"**é‡åŒ–**: {res}")
            opinions['quant'] = res
    else:
        quant_ctx = "Market Data Offline"

    # --- STEP C: DRAFTING ---
    with st.chat_message("assistant", avatar="ğŸ“"):
        st.write("âœï¸ æ­£åœ¨æ’°å†™ç ”æŠ¥è‰æ¡ˆ...")
        full_ctx = f"Opinions:{json.dumps(opinions, ensure_ascii=False)}\nMarket:{quant_ctx}"
        report_draft, _ = call_agent("Analyst", SPECIFIC_MODELS["DEEPSEEK"], 
                            "ä½ æ˜¯é¦–å¸­åˆ†æå¸ˆã€‚å†™ä¸€ä»½ç»“æ„åŒ–ç ”æŠ¥ï¼ŒåŒ…å«é€»è¾‘ã€é£é™©å’Œç»“è®ºã€‚", full_ctx)
        st.markdown(report_draft)

    # --- STEP D: CHIEF REVIEW ---
    with st.chat_message("assistant", avatar="ğŸ‘¨â€ğŸ”¬"):
        st.write("ğŸ•µï¸ **é¦–å¸­ç ”ç©¶å‘˜ (Kimi)** æ­£åœ¨å®¡æ ¸...")
        
        review_prompt = f"""
        ä½ æ˜¯é¦–å¸­ç ”ç©¶å‘˜ã€‚å®¡æŸ¥ç ”æŠ¥ã€‚
        1. è‹¥ä¿¡æ¯ä¸¥é‡ç¼ºå¤±ï¼Œè¾“å‡ºæŒ‡ä»¤ï¼šREWORK: [MACRO/MESO/MICRO]
        2. è‹¥é€šè¿‡ï¼Œè¾“å‡ºæœ€ç»ˆæŠ•èµ„å»ºè®®ã€‚
        ç ”æŠ¥: {report_draft}
        """
        review_res, thinking = call_agent("Chief", SPECIFIC_MODELS["KIMI"], review_prompt, "å¼€å§‹å®¡æ ¸", thinking_needed=True)
        
        if thinking:
            with st.expander("ğŸ§  æ€è€ƒè¿‡ç¨‹", expanded=True):
                st.markdown(f"_{thinking}_")
        
        if "REWORK:" in review_res and st.session_state.retry_count < 1:
            match = re.search(r"REWORK:\s*(\w+)", review_res)
            field = match.group(1).lower() if match else "micro"
            # Fuzzy map to keys
            if "macro" in field: field = "macro"
            elif "indus" in field or "meso" in field: field = "meso"
            else: field = "micro"
            
            st.session_state.last_rework_field = field
            st.warning(f"ğŸš¨ é©³å›ï¼šè¦æ±‚è¡¥å…… **{field}** é¢†åŸŸä¿¡æ¯ã€‚æ­£åœ¨æ‰§è¡Œ...")
            
            new_query = f"{ticker} {field} analysis latest news details"
            new_info = search_web(new_query, "general")
            
            st.session_state.raw_news[field].extend(new_info)
            st.session_state.retry_count += 1
            st.rerun()
            
        else:
            st.success("âœ… å®¡æ ¸é€šè¿‡")
            st.markdown(f"### ğŸ† æœ€ç»ˆå†³ç­–\n{review_res}")
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": f"### ğŸ“‘ æœ€ç»ˆç ”æŠ¥ ({ticker})\n\n{report_draft}\n\n---\n**ğŸ† é¦–å¸­å†³ç­–**: {review_res}", 
                "avatar": "ğŸ‘¨â€ğŸ”¬", 
                "thinking": thinking
            })
            st.session_state.process_status = "DONE"
