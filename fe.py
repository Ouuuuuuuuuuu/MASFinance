import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from tavily import TavilyClient
from openai import OpenAI
import plotly.graph_objects as go
import json
import concurrent.futures
import time
import re
import requests

# --- PAGE SETUP ---
st.set_page_config(
    page_title="MAS è”åˆç ”æŠ¥ç»ˆç«¯ v4.1",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS STYLING ---
st.markdown("""
<style>
    .stApp { background-color: #f8f9fa; color: #1f2937; }
    .report-box { background-color: #ffffff; padding: 20px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }
    .stChatMessage { background-color: transparent; }
    .stChatMessage .stChatMessageAvatar { background-color: #e5e7eb; }
    div[data-testid="metric-container"] { background-color: #ffffff; border: 1px solid #e5e7eb; padding: 10px; border-radius: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    /* Thinking Process Style */
    .thinking-box {
        font-size: 0.85em;
        color: #6b7280;
        border-left: 3px solid #e5e7eb;
        padding-left: 10px;
        margin-bottom: 10px;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# --- CONFIGURATION & SECRETS ---
# ä¿®æ”¹è¯´æ˜ï¼šç›´æ¥ä» st.secrets è¯»å–æ‰€æœ‰ Keysï¼Œä¸å†æä¾›ä¾§è¾¹æ è¾“å…¥
try:
    SECRETS = st.secrets["api_keys"]
    silicon_flow_key = SECRETS["silicon_flow"]
    tavily_key = SECRETS["tavily"]
    alpha_vantage_key = SECRETS["alpha_vantage"]
except Exception as e:
    st.error("âŒ å¯åŠ¨å¤±è´¥ï¼šæœªæ£€æµ‹åˆ°å®Œæ•´çš„ API Keys é…ç½®")
    st.info("""
    è¯·ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `.streamlit/secrets.toml` æ–‡ä»¶åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
    
    ```toml
    [api_keys]
    silicon_flow = "sk-..."
    tavily = "tvly-..."
    alpha_vantage = "..."
    ```
    """)
    st.stop()

# --- MODEL CONFIG ---
SPECIFIC_MODELS = {
    "ROUTER": "Qwen/Qwen2.5-72B-Instruct",
    "VERIFIER": "Qwen/Qwen2.5-72B-Instruct",
    "MACRO": "MiniMaxAI/MiniMax-M2",
    "MESO": "MiniMaxAI/MiniMax-M2",
    "MICRO": "MiniMaxAI/MiniMax-M2",
    "QUANT": "deepseek-ai/DeepSeek-V3",
    "WRITER": "deepseek-ai/DeepSeek-V3",
    "CHIEF": "moonshotai/Kimi-K2-Thinking"
}

# --- STATE INITIALIZATION ---
def init_state():
    defaults = {
        "messages": [{"role": "assistant", "content": "é¦–å¸­ç ”ç©¶å‘˜å°±ä½ã€‚è¯·ä¸‹è¾¾è°ƒç ”æŒ‡ä»¤ã€‚", "avatar": "ğŸ‘¨â€ğŸ”¬"}],
        "process_status": "IDLE", # IDLE, VERIFYING, ANALYZING, DONE
        "ticker": None,
        "market_data": None,
        "raw_news": {},     # {field: [news1, news2]}
        "opinions": {},     # {field: "analysis text"} -> ç”¨äºå®ç°ç»­å†™ä¸è¦†ç›–
        "retry_count": 0,
        "last_rework_field": None,
        "user_query": "",
        "verification_fail": False
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

init_state()

# --- SIDEBAR ---
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    # ç§»é™¤äº†æ‰€æœ‰ Inputï¼Œä»…æ˜¾ç¤ºçŠ¶æ€
    st.success("âœ… API å¯†é’¥å·²åŠ è½½")
    st.caption("Environment: Protected")

    st.divider()
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å² & é‡ç½®"):
        st.session_state.clear()
        st.rerun()

# --- UTILS WITH CACHING ---

@st.cache_data(ttl=3600)
def fetch_from_alphavantage(ticker, api_key):
    if not api_key: return None
    try:
        url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={api_key}&outputsize=compact"
        r = requests.get(url, timeout=10)
        data = r.json()
        if "Time Series (Daily)" not in data: return None
        
        df = pd.DataFrame.from_dict(data["Time Series (Daily)"], orient='index')
        df = df.rename(columns={"4. close": "Close", "1. open": "Open", "2. high": "High", "3. low": "Low"})
        df = df.astype(float).sort_index()
        return df
    except:
        return None

@st.cache_data(ttl=3600)
def fetch_from_yfinance(ticker):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="6mo")
        if hist.empty: return None, None
        return hist, stock.info
    except:
        return None, None

def calculate_technical_indicators(df):
    if df is None or df.empty: return df
    df = df.copy()
    exp12 = df['Close'].ewm(span=12, adjust=False).mean()
    exp26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp12 - exp26
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['Signal_Line']
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

def fetch_market_data(ticker, av_key):
    hist, info = fetch_from_yfinance(ticker)
    source = "YFinance"
    
    if hist is None:
        hist = fetch_from_alphavantage(ticker, av_key)
        info = {}
        source = "AlphaVantage"
    
    if hist is None or hist.empty:
        return {"status": "OFFLINE", "error": "Data unavailable"}
        
    hist = calculate_technical_indicators(hist)
    
    try:
        last_close = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2]
        change_pct = ((last_close - prev_close) / prev_close) * 100
        
        return {
            "status": f"ONLINE ({source})",
            "symbol": ticker.upper(),
            "name": info.get('longName', ticker) if info else ticker,
            "price": last_close,
            "change_pct": change_pct,
            "pe": info.get('trailingPE', 'N/A') if info else 'N/A',
            "cap": info.get('marketCap', 'N/A') if info else 'N/A',
            "history_df": hist,
            "last_macd": hist['MACD_Hist'].iloc[-1],
            "last_rsi": hist['RSI'].iloc[-1]
        }
    except Exception as e:
        return {"status": "ERROR", "error": str(e)}

@st.cache_data(ttl=1800)
def search_web(query, topic="general", _api_key=None):
    if not _api_key: return ["Error: Missing Tavily API Key"]
    try:
        tavily = TavilyClient(api_key=_api_key)
        res = tavily.search(query=query, topic=topic, max_results=5)
        return [f"- {r['title']}: {r['content'][:350]}" for r in res['results']]
    except Exception as e:
        return [f"Search Error: {str(e)}"]

def get_llm_client(api_key):
    return OpenAI(api_key=api_key, base_url="https://api.siliconflow.cn/v1")

def call_agent(agent_name, model_id, system_prompt, user_prompt, thinking_needed=False):
    client = get_llm_client(silicon_flow_key)
    
    final_sys_prompt = system_prompt + """
    \nã€è¾“å‡ºè§„èŒƒã€‘
    1. è¯­è¨€ï¼šç®€ä½“ä¸­æ–‡ (Simplified Chinese)ã€‚
    2. æ ¼å¼ï¼šMarkdownï¼Œç¦æ­¢ä½¿ç”¨ä¸€çº§æ ‡é¢˜(#)ï¼Œä»ä¸‰çº§(###)å¼€å§‹ã€‚
    3. é£æ ¼ï¼šä¸“ä¸šã€å®¢è§‚ã€é‡‘èç ”æŠ¥é£ã€‚
    """
    
    if thinking_needed:
        final_sys_prompt += "\nIMPORTANT: First output thinking process in <thinking>...</thinking>, then final answer."

    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": final_sys_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2048
        )
        content = response.choices[0].message.content
        
        thinking = ""
        if "<thinking>" in content:
            match = re.search(r"<thinking>(.*?)</thinking>", content, re.DOTALL)
            if match:
                thinking = match.group(1).strip()
                content = re.sub(r"<thinking>.*?</thinking>", "", content, flags=re.DOTALL).strip()
        
        return content, thinking
    except Exception as e:
        return f"âš ï¸ {agent_name} Error: {str(e)}", ""

def extract_json_from_markdown(text):
    try:
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            return json.loads(match.group(0))
    except:
        pass
    return None

# --- MAIN LOGIC ---

# 1. Display History
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.markdown(msg["content"])
        if msg.get("thinking"):
            with st.expander("ğŸ§  æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown(f"_{msg['thinking']}_")

# 2. Input
if user_input := st.chat_input("è¯·è¾“å…¥è‚¡ç¥¨åç§°æˆ–ä»£ç ..."):
    # æ£€æŸ¥ Keys æ˜¯å¦å­˜åœ¨
    if not (silicon_flow_key and tavily_key):
        st.error("é…ç½®é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„ API Key")
        st.stop()
        
    # Reset State for new query
    st.session_state.process_status = "VERIFYING"
    st.session_state.ticker = None
    st.session_state.market_data = None
    st.session_state.raw_news = {}
    st.session_state.opinions = {} # Clear opinions for new stock
    st.session_state.retry_count = 0
    st.session_state.last_rework_field = None
    st.session_state.verification_fail = False
    st.session_state.user_query = user_input
    
    st.session_state.messages.append({"role": "user", "content": user_input, "avatar": "ğŸ‘¤"})
    st.rerun()

# 3. VERIFICATION PHASE
if st.session_state.process_status == "VERIFYING":
    with st.chat_message("assistant", avatar="ğŸ‘©â€ğŸ’¼"):
        st.write("ğŸ” è‘£ç§˜æ­£åœ¨æ ¸å®ä»£ç ...")
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            f_en = executor.submit(search_web, f"{st.session_state.user_query} stock ticker Yahoo Finance", "general", tavily_key)
            f_cn = executor.submit(search_web, f"{st.session_state.user_query} è‚¡ç¥¨ä»£ç ", "general", tavily_key)
            search_res = f_en.result() + f_cn.result()
            
        search_ctx = "\n".join(search_res)
        
        router_prompt = f"""
        User Query: "{st.session_state.user_query}"
        Search Results: {search_ctx}
        
        Task: Extract the Yahoo Finance Ticker.
        Rules:
        1. A-Share: 6 digits + .SS or .SZ (e.g., 600519.SS)
        2. HK Share: 4 digits + .HK
        3. US Share: Ticker symbol (e.g., TSLA)
        4. Return JSON: {{'ticker': '...', 'company_name': '...'}}
        """
        
        res, _ = call_agent("Router", SPECIFIC_MODELS["ROUTER"], "Extract Ticker JSON.", router_prompt)
        json_data = extract_json_from_markdown(res)
        
        if json_data and 'ticker' in json_data:
            candidate = json_data['ticker']
            candidate_name = json_data.get('company_name', 'Unknown')
            
            verify_prompt = f"""
            User Input: "{st.session_state.user_query}"
            Extracted Ticker: "{candidate}"
            Extracted Name: "{candidate_name}"
            
            Does this ticker likely match the user's intent?
            Return JSON: {{'match': true/false, 'reason': '...'}}
            """
            v_res, _ = call_agent("Verifier", SPECIFIC_MODELS["VERIFIER"], "Verify intent JSON.", verify_prompt)
            v_json = extract_json_from_markdown(v_res)
            
            if v_json and v_json.get('match'):
                st.session_state.ticker = candidate
                st.session_state.process_status = "ANALYZING"
                st.success(f"âœ… é”å®šæ ‡çš„: {candidate_name} ({candidate})")
                time.sleep(1)
                st.rerun()
            else:
                st.session_state.ticker = candidate
                st.session_state.verification_fail = True
                # 7. ä¼˜åŒ–æç¤ºè¯­ï¼šæ‚¨æ˜¯ä¸æ˜¯æƒ³æ‰¾...
                st.warning(f"âš ï¸ æœªå®Œå…¨åŒ¹é…ã€‚æ‚¨æ˜¯ä¸æ˜¯æƒ³æ‰¾ï¼š**{candidate_name} ({candidate})**ï¼Ÿ")
                col1, col2 = st.columns(2)
                if col1.button("âœ… æ˜¯çš„ï¼Œç»§ç»­åˆ†æ"):
                    st.session_state.process_status = "ANALYZING"
                    st.rerun()
                if col2.button("âŒ ä¸æ˜¯ï¼Œåœæ­¢"):
                    st.session_state.process_status = "IDLE"
                    st.stop()
        else:
            st.error("âŒ æ— æ³•è¯†åˆ«æœ‰æ•ˆä»£ç ï¼Œè¯·å°è¯•è¾“å…¥æ›´ç²¾ç¡®çš„åç§°ã€‚")
            st.session_state.process_status = "IDLE"

# 4. ANALYSIS PHASE
if st.session_state.process_status == "ANALYZING" and st.session_state.ticker:
    ticker = st.session_state.ticker
    
    # --- FETCH DATA ---
    if not st.session_state.market_data:
        with st.status("ğŸ“¡ æ­£åœ¨è·å–è¡Œæƒ…ä¸æƒ…æŠ¥...", expanded=True) as status:
            mkt = fetch_market_data(ticker, alpha_vantage_key)
            st.session_state.market_data = mkt
            
            if mkt['status'] == "OFFLINE":
                st.error("è¡Œæƒ…æ•°æ®è·å–å¤±è´¥")
            
            queries = {
                "macro": "global macro economy news market trends",
                "meso": f"{ticker} industry competitors market share",
                "micro": f"{ticker} stock news financial reports analysis",
            }
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {k: executor.submit(search_web, v, "news", tavily_key) for k, v in queries.items()}
                for k, f in futures.items():
                    st.session_state.raw_news[k] = f.result()
            
            status.update(label="âœ… æ•°æ®å°±ç»ª", state="complete")

    # --- RENDER DASHBOARD ---
    mkt = st.session_state.market_data
    if mkt and mkt['status'] != "OFFLINE":
        with st.container():
            st.markdown(f"### ğŸ“‰ {mkt.get('name')} ({mkt.get('symbol')})")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ä»·æ ¼", f"{mkt['price']:.2f}", f"{mkt['change_pct']:.2f}%")
            c2.metric("PE", mkt.get('pe'))
            c3.metric("RSI (14)", f"{mkt.get('last_rsi', 0):.1f}")
            c4.metric("MACD", f"{mkt.get('last_macd', 0):.3f}")
    
    st.divider()
    
    # --- AGENT MEETING ---
    news = st.session_state.raw_news
    
    # Helper to render or get cached opinion (å®ç°äº†â€œç»­å†™ä¸è¦†ç›–â€é€»è¾‘)
    def render_opinion(role, avatar, key, model, prompt_tmpl):
        with st.chat_message("assistant", avatar=avatar):
            is_rework_target = st.session_state.last_rework_field == key
            existing_opinion = st.session_state.opinions.get(key, None)
            
            # é€»è¾‘ï¼š
            # 1. å¦‚æœå·²æœ‰è§‚ç‚¹ ä¸” ä¸æ˜¯å½“å‰éœ€è¦è¿”å·¥çš„é¢†åŸŸ -> ç›´æ¥å±•ç¤ºæ—§è§‚ç‚¹ (çœé’± & ç¨³å®š)
            # 2. å¦‚æœæ˜¯è¿”å·¥é¢†åŸŸ -> ä¼ å…¥æ—§è§‚ç‚¹ï¼Œè¦æ±‚"ç»­å†™/ä¿®æ­£"
            # 3. å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ -> åˆå§‹ç”Ÿæˆ
            
            if existing_opinion and not is_rework_target:
                st.markdown(f"**{role} (å·²å½’æ¡£)**: {existing_opinion}")
                return existing_opinion
            
            # æ„é€  Prompt
            current_news = str(news.get(key, ''))
            
            if is_rework_target and existing_opinion:
                # 6. è¿”å·¥å†…å®¹ç»§ç»­å†™ï¼Œä¸è¦†ç›–
                final_prompt = f"""
                {prompt_tmpl}
                
                ã€é‡è¦ã€‘è¿™æ˜¯ä½ ä¹‹å‰çš„åˆ†æï¼š
                "{existing_opinion}"
                
                è¿™æ˜¯æ–°è¡¥å……çš„æƒ…æŠ¥ï¼š
                {current_news}
                
                è¯·åŸºäºæ–°æƒ…æŠ¥å¯¹ä¹‹å‰çš„åˆ†æè¿›è¡Œ**è¡¥å……å’Œä¿®è®¢**ã€‚ä¸è¦å®Œå…¨æ¨ç¿»ï¼Œä¿ç•™æœ‰ä»·å€¼çš„æ—§è§‚ç‚¹ï¼Œå°†æ–°å‘ç°æ•´åˆè¿›å»ã€‚
                """
                st.info("ğŸ”„ æ­£åœ¨åŸºäºæ–°æƒ…æŠ¥ä¿®è®¢è§‚ç‚¹...")
            else:
                final_prompt = f"{prompt_tmpl}\næƒ…æŠ¥:{current_news}"

            res, _ = call_agent(role, model, f"ä½ æ˜¯{role}åˆ†æå¸ˆã€‚", final_prompt)
            st.markdown(f"**{role}**: {res}")
            
            # Save to session state
            st.session_state.opinions[key] = res
            return res

    st.subheader(f"ğŸ—£ï¸ æŠ•ç ”ä¼šè®® (ç¬¬ {st.session_state.retry_count + 1} è½®)")
    
    # Render Agents
    render_opinion("Macro", "ğŸŒ", "macro", SPECIFIC_MODELS["MACRO"], "ç®€è¿°å®è§‚ç¯å¢ƒã€‚")
    render_opinion("Industry", "ğŸ­", "meso", SPECIFIC_MODELS["MESO"], f"åˆ†æ {ticker} è¡Œä¸šç«äº‰æ ¼å±€ã€‚")
    render_opinion("Company", "ğŸ”", "micro", SPECIFIC_MODELS["MICRO"], f"åˆ†æ {ticker} ä¸ªè‚¡åŸºæœ¬é¢ã€‚")
    
    # Quant (Always run if market data exists, quick check)
    if mkt and mkt['status'] != "OFFLINE":
        with st.chat_message("assistant", avatar="ğŸ’¹"):
            q_ctx = f"Price:{mkt['price']}, RSI:{mkt.get('last_rsi')}, MACD:{mkt.get('last_macd')}"
            res, _ = call_agent("Quant", SPECIFIC_MODELS["QUANT"], "æŠ€æœ¯é¢åˆ†æå¸ˆ", f"åŸºäºæ•°æ®è¯„ä»·è¶‹åŠ¿ï¼š{q_ctx}")
            st.markdown(f"**é‡åŒ–**: {res}")
            st.session_state.opinions['quant'] = res

    # --- DRAFTING ---
    with st.chat_message("assistant", avatar="ğŸ“"):
        st.write("âœï¸ æ­£åœ¨æ’°å†™è‰æ¡ˆ...")
        # Analyst uses all current opinions (some cached, some updated)
        draft_ctx = f"Opinions: {json.dumps(st.session_state.opinions, ensure_ascii=False)}"
        report_draft, _ = call_agent("Writer", SPECIFIC_MODELS["WRITER"], "é¦–å¸­åˆ†æå¸ˆã€‚æ•´åˆç ”æŠ¥ã€‚", draft_ctx)
        st.markdown(report_draft)

    # --- CHIEF REVIEW ---
    with st.chat_message("assistant", avatar="ğŸ‘¨â€ğŸ”¬"):
        st.write("ğŸ•µï¸ é¦–å¸­ç ”ç©¶å‘˜å®¡æ ¸ä¸­...")
        review_prompt = f"ç ”æŠ¥è‰æ¡ˆ:\n{report_draft}\n\næŒ‡ä»¤ï¼šè‹¥ä¿¡æ¯ä¸è¶³ï¼Œè¾“å‡º REWORK: [MACRO/MESO/MICRO]ã€‚å¦åˆ™è¾“å‡ºæœ€ç»ˆç»“è®ºã€‚"
        review_res, thinking = call_agent("Chief", SPECIFIC_MODELS["CHIEF"], "é¦–å¸­ç ”ç©¶å‘˜ã€‚ä¸¥æ ¼å®¡æ ¸ã€‚", review_prompt, thinking_needed=True)
        
        if thinking:
            with st.expander("ğŸ§  é¦–å¸­æ€è€ƒè¿‡ç¨‹", expanded=True):
                st.markdown(f"_{thinking}_")
        
        # Logic for Rework
        if "REWORK:" in review_res and st.session_state.retry_count < 1:
            match = re.search(r"REWORK:\s*(\w+)", review_res)
            field = match.group(1).lower() if match else "micro"
            
            field_map = {"macro": "macro", "industry": "meso", "meso": "meso", "company": "micro", "micro": "micro"}
            target_key = field_map.get(field, "micro")
            
            st.warning(f"ğŸš¨ é©³å›ï¼šéœ€è¡¥å…… {target_key} é¢†åŸŸä¿¡æ¯ã€‚æ­£åœ¨æ‰§è¡Œ...")
            
            # 5. æ™ºèƒ½è¡¥å……æœç´¢ (Agent æ„é€ å…³é”®è¯)
            st.write(f"ğŸ” æ­£åœ¨é’ˆå¯¹ {target_key} è¿›è¡Œæ·±åº¦æŒ–æ˜...")
            keyword_prompt = f"é’ˆå¯¹è‚¡ç¥¨ {ticker}ï¼Œç›®å‰ {target_key} é¢†åŸŸä¿¡æ¯ç¼ºå¤±ã€‚è¯·ç”Ÿæˆ3ä¸ªå…·ä½“çš„Googleæœç´¢å…³é”®è¯ç”¨äºæŒ–æ˜è¯¥é¢†åŸŸçš„æ·±å±‚ä¿¡æ¯ã€‚åªè¿”å›å…³é”®è¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚"
            keywords, _ = call_agent("Searcher", SPECIFIC_MODELS["VERIFIER"], "Search Expert", keyword_prompt)
            
            new_query = f"{ticker} {keywords}"
            new_info = search_web(new_query, "general", tavily_key)
            
            if target_key in st.session_state.raw_news:
                st.session_state.raw_news[target_key].extend(new_info)
            else:
                 st.session_state.raw_news[target_key] = new_info
            
            st.session_state.retry_count += 1
            st.session_state.last_rework_field = target_key
            time.sleep(2)
            st.rerun()
            
        else:
            st.success("âœ… å®¡æ ¸é€šè¿‡")
            st.markdown(f"### ğŸ† æœ€ç»ˆå†³ç­–\n{review_res}")
            
            final_content = f"### ğŸ“‘ æœ€ç»ˆç ”æŠ¥ ({ticker})\n\n{report_draft}\n\n---\n**ğŸ† é¦–å¸­å†³ç­–**: {review_res}"
            st.session_state.messages.append({"role": "assistant", "content": final_content, "avatar": "ğŸ‘¨â€ğŸ”¬", "thinking": thinking})
            st.session_state.process_status = "DONE"
            if st.button("å¼€å§‹æ–°ç ”ç©¶"):
                st.session_state.process_status = "IDLE"
                st.rerun()
