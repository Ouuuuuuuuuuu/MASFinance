import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from tavily import TavilyClient
from openai import OpenAI
import plotly.graph_objects as go
import json
import concurrent.futures
import time
import random
import requests
import feedparser
import re

# --- PAGE SETUP ---
st.set_page_config(
    page_title="MAS è”åˆç ”æŠ¥ç»ˆç«¯ v3.1 (Fix)",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS STYLING ---
st.markdown("""
<style>
    .stApp { background-color: #ffffff; color: #1f2937; }
    .stTextInput > div > div > input { background-color: #f3f4f6; color: #1f2937; }
    .stChatMessage .stChatMessageAvatar { background-color: #e5e7eb; border-radius: 50%; }
    div[data-testid="metric-container"] { background-color: #f9fafb; border: 1px solid #e5e7eb; padding: 10px; border-radius: 8px; }
    
    .thinking-box {
        font-size: 0.85em;
        color: #6b7280;
        border-left: 3px solid #e5e7eb;
        padding-left: 10px;
        margin-bottom: 10px;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# --- SESSION STATE INITIALIZATION (CRITICAL FIX) ---
# ä¿®å¤é€»è¾‘é”™è¯¯æ ¸å¿ƒï¼šæ‰€æœ‰è·¨ Rerun çš„æ•°æ®å¿…é¡»å­˜å…¥ Session State
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "é¦–å¸­ç ”ç©¶å‘˜å°±ä½ã€‚è¯·ä¸‹è¾¾è°ƒç ”æŒ‡ä»¤ï¼ˆå¦‚ï¼šåˆ†æ ç‰¹æ–¯æ‹‰ï¼‰ã€‚", "avatar": "ğŸ‘¨â€ğŸ”¬"}]
if "process_status" not in st.session_state:
    st.session_state.process_status = "IDLE" # IDLE, ANALYZING, REVIEWING, DONE
if "ticker" not in st.session_state:
    st.session_state.ticker = None
if "market_data" not in st.session_state:
    st.session_state.market_data = None
if "raw_news" not in st.session_state:
    st.session_state.raw_news = {}
if "retry_count" not in st.session_state:
    st.session_state.retry_count = 0
if "final_report" not in st.session_state:
    st.session_state.final_report = None

# --- SIDEBAR & SECRETS ---
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    st.subheader("ğŸ”‘ é‰´æƒè®¾ç½®")
    
    # ä¼˜å…ˆå°è¯•ä» st.secrets è¯»å–ï¼Œå¦‚æœæ²¡é…ç½®ï¼Œåˆ™æ˜¾ç¤ºè¾“å…¥æ¡†
    # è¿™ç§æ–¹å¼æ—¢å®‰å…¨ï¼ˆGitHubä¸æ³„éœ²ï¼‰åˆæ–¹ä¾¿ï¼ˆæœ¬åœ°æµ‹è¯•å¯ä»¥ç›´æ¥å¡«ï¼‰
    
    default_sf_key = st.secrets.get("SILICON_FLOW_KEY", "")
    silicon_flow_key = st.text_input("SiliconFlow Key", value=default_sf_key, type="password")
    
    default_tavily = st.secrets.get("TAVILY_API_KEY", "")
    tavily_api_key = st.text_input("Tavily Key", value=default_tavily, type="password")
    
    default_av = st.secrets.get("ALPHA_VANTAGE_KEY", "")
    alpha_vantage_key = st.text_input("Alpha Vantage Key", value=default_av, type="password")

    if not silicon_flow_key or not tavily_api_key:
        st.warning("âš ï¸ è¯·å¡«å…¥å¿…è¦çš„ API Key")
    
    st.divider()
    if st.button("ğŸ”„ é‡ç½®ç³»ç»ŸçŠ¶æ€"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# --- ROBUST UTILS ---

def extract_json_from_markdown(text):
    """Robust JSON extraction using Regex to find { ... } block."""
    try:
        # å°è¯•ç›´æ¥è§£æ
        return json.loads(text)
    except json.JSONDecodeError:
        # æ­£åˆ™æå–ç¬¬ä¸€ä¸ª JSON å¯¹è±¡
        match = re.search(r"\{.*\}", text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(0))
            except:
                pass
    return None

def get_llm_client():
    if not silicon_flow_key: return None
    return OpenAI(api_key=silicon_flow_key, base_url="https://api.siliconflow.cn/v1")

def get_tavily_client():
    return TavilyClient(api_key=tavily_api_key)

def calculate_technical_indicators(df):
    if df.empty: return df
    exp12 = df['Close'].ewm(span=12, adjust=False).mean()
    exp26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = exp12 - exp26
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['Signal_Line']
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    return df

def fetch_market_data(ticker):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="6mo")
        if hist.empty: raise ValueError("Empty Data")
        hist = calculate_technical_indicators(hist)
        info = stock.info
        return {
            "status": "ONLINE (YF)",
            "symbol": ticker.upper(),
            "name": info.get('longName', ticker),
            "price": info.get('currentPrice', hist['Close'].iloc[-1]),
            "change_pct": ((hist['Close'].iloc[-1] - hist['Close'].iloc[-2])/hist['Close'].iloc[-2])*100,
            "pe": info.get('trailingPE', 'N/A'),
            "cap": info.get('marketCap', 'N/A'),
            "history_df": hist,
            "last_macd": {"hist": hist['MACD_Hist'].iloc[-1]},
            "last_rsi": hist['RSI'].iloc[-1]
        }
    except:
        return {"status": "OFFLINE", "error": "Market data unavailable"}

def search_web(query, topic="general"):
    try:
        tavily = get_tavily_client()
        res = tavily.search(query=query, topic=topic, max_results=5)
        return [f"- {r['title']}: {r['content'][:300]}" for r in res['results']]
    except Exception as e:
        return [f"Search Error: {str(e)}"]

def call_agent(agent_name, model_id, system_prompt, user_prompt, thinking_needed=False):
    client = get_llm_client()
    if not client: return "API Key Missing", ""
    
    final_sys_prompt = system_prompt
    if thinking_needed:
        final_sys_prompt += "\nIMPORTANT: You MUST first output your internal thinking process wrapped in <thinking>...</thinking> tags, then output your final response."

    try:
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": final_sys_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2048
        )
        content = response.choices[0].message.content
        
        # Parse Thinking
        thinking = ""
        if "<thinking>" in content:
            match = re.search(r"<thinking>(.*?)</thinking>", content, re.DOTALL)
            if match:
                thinking = match.group(1).strip()
                content = re.sub(r"<thinking>.*?</thinking>", "", content, flags=re.DOTALL).strip()
        
        return content, thinking
    except Exception as e:
        return f"âš ï¸ {agent_name} Error: {str(e)}", ""

# --- MODEL MAP ---
SPECIFIC_MODELS = {
    "DEEPSEEK": "deepseek-ai/DeepSeek-V3", 
    "KIMI": "moonshotai/Kimi-K2-Thinking",
    "MINIMAX": "MiniMaxAI/MiniMax-M2",
    "QWEN": "Qwen/Qwen2.5-72B-Instruct"
}

# --- MAIN UI LOGIC ---

st.title("ğŸ¦ MAS è”åˆç ”æŠ¥ç»ˆç«¯ v3.1")
st.caption(f"æ··åˆæ¨¡å‹å¼•æ“: Qwen (è·¯ç”±) | MiniMax (æƒ…æŠ¥) | DeepSeek (åˆ†æ) | Kimi (é¦–å¸­ç ”ç©¶)")

# 1. Chat History Rendering
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.markdown(msg["content"])
        if msg.get("thinking"):
            with st.expander("ğŸ§  æ€è€ƒè¿‡ç¨‹ (Thinking Chain)", expanded=False):
                st.markdown(f"_{msg['thinking']}_")

# 2. Input Handler
if user_input := st.chat_input("è¯·è¾“å…¥æ ‡çš„..."):
    if not silicon_flow_key or not tavily_api_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        st.stop()

    # Clear previous session data for new query
    st.session_state.ticker = None
    st.session_state.market_data = None
    st.session_state.raw_news = {}
    st.session_state.retry_count = 0
    st.session_state.final_report = None
    
    st.session_state.messages.append({"role": "user", "content": user_input, "avatar": "ğŸ‘¤"})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)

    # Router Step
    with st.chat_message("assistant", avatar="ğŸ‘©â€ğŸ’¼"):
        st.write("ğŸ”„ è‘£ç§˜æ­£åœ¨ç«‹é¡¹...")
        res, _ = call_agent("Router", SPECIFIC_MODELS["QWEN"], 
                            "æå–Yahoo Tickerã€‚è¿”å›JSON {'ticker': '...'}", user_input)
        
        json_data = extract_json_from_markdown(res) # Robust JSON Parsing
        
        if json_data and 'ticker' in json_data:
            st.session_state.ticker = json_data['ticker']
            st.markdown(f"âœ… æ ‡çš„ç¡®è®¤ï¼š**{st.session_state.ticker}**")
            st.session_state.process_status = "ANALYZING"
            st.rerun() # Force rerun to enter analysis phase with state
        else:
            st.error(f"æ— æ³•è¯†åˆ«æ ‡çš„ï¼ŒAIè¿”å›ï¼š{res}")
            st.stop()

# 3. Analysis Process (Triggered by State)
if st.session_state.process_status == "ANALYZING" and st.session_state.ticker:
    
    ticker = st.session_state.ticker
    
    # --- STEP A: FETCH DATA (Only if missing) ---
    if not st.session_state.market_data:
        with st.status("ğŸ“¡ æ­£åœ¨è¿›è¡Œå…¨ç½‘æƒ…æŠ¥æœé›†...", expanded=True) as status:
            mkt = fetch_market_data(ticker)
            if mkt['status'] == "OFFLINE":
                st.error("è¡Œæƒ…æ•°æ®è·å–å¤±è´¥")
                st.stop()
            st.session_state.market_data = mkt
            
            queries = {
                "macro": "global macro economy news market trends",
                "meso": f"{ticker} industry competitors market share",
                "micro": f"{ticker} stock news financial reports analysis",
                "pol": "international geopolitics trade war impact"
            }
            
            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {k: executor.submit(search_web, v, "news" if k != "meso" else "general") for k, v in queries.items()}
                for k, f in futures.items():
                    st.session_state.raw_news[k] = f.result()
            
            status.update(label="âœ… åˆå§‹æƒ…æŠ¥å·²å°±ç»ª", state="complete")
    
    # --- STEP B: MEETING (Display Opinions) ---
    mkt = st.session_state.market_data
    news = st.session_state.raw_news
    opinions = {}
    
    st.subheader(f"ğŸ—£ï¸ æŠ•ç ”ä¼šè®® (Round {st.session_state.retry_count + 1})")
    
    # Agents speak
    with st.chat_message("assistant", avatar="ğŸŒ"):
        res, _ = call_agent("Macro", SPECIFIC_MODELS["MINIMAX"], "ç®€è¿°å®è§‚ç¯å¢ƒã€‚", str(news['macro']))
        st.markdown(f"**å®è§‚**: {res}")
        opinions['macro'] = res

    with st.chat_message("assistant", avatar="ğŸ­"):
        res, _ = call_agent("Meso", SPECIFIC_MODELS["MINIMAX"], f"åˆ†æ {ticker} è¡Œä¸šã€‚", str(news['meso']))
        st.markdown(f"**è¡Œä¸š**: {res}")
        opinions['meso'] = res

    with st.chat_message("assistant", avatar="ğŸ”"):
        res, _ = call_agent("Micro", SPECIFIC_MODELS["MINIMAX"], f"åˆ†æ {ticker} ä¸ªè‚¡ã€‚", str(news['micro']))
        st.markdown(f"**ä¸ªè‚¡**: {res}")
        opinions['micro'] = res
    
    with st.chat_message("assistant", avatar="ğŸ’¹"):
        quant_ctx = f"Price:{mkt['price']}, PE:{mkt['pe']}, RSI:{mkt['last_rsi']:.1f}"
        res, _ = call_agent("Finance", SPECIFIC_MODELS["DEEPSEEK"], "è¯„ä»·ä¼°å€¼ä¸æŠ€æœ¯é¢ã€‚", quant_ctx)
        st.markdown(f"**é‡åŒ–**: {res}")
        opinions['quant'] = res

    # --- STEP C: DRAFTING ---
    with st.chat_message("assistant", avatar="ğŸ“"):
        st.write("âœï¸ æ­£åœ¨æ’°å†™ç ”æŠ¥è‰æ¡ˆ...")
        full_ctx = f"Opinions:{json.dumps(opinions, ensure_ascii=False)}\nMarket:{quant_ctx}"
        report_draft, _ = call_agent("Analyst", SPECIFIC_MODELS["DEEPSEEK"], 
                            "å†™ä¸€ä»½ç»“æ„åŒ–ç ”æŠ¥ï¼ŒåŒ…å«é€»è¾‘ã€é£é™©å’Œç»“è®ºã€‚", full_ctx)
        st.markdown(report_draft)

    # --- STEP D: CHIEF REVIEW ---
    with st.chat_message("assistant", avatar="ğŸ‘¨â€ğŸ”¬"):
        st.write("ğŸ•µï¸ **é¦–å¸­ç ”ç©¶å‘˜ (Kimi)** æ­£åœ¨å®¡æ ¸...")
        
        review_prompt = f"""
        ä½ æ˜¯é¦–å¸­ç ”ç©¶å‘˜ã€‚å®¡æŸ¥ç ”æŠ¥ã€‚
        1. è‹¥ä¿¡æ¯ä¸¥é‡ç¼ºå¤±ï¼Œè¾“å‡ºæŒ‡ä»¤ï¼šREWORK: [MACRO/MESO/MICRO]
        2. è‹¥é€šè¿‡ï¼Œè¾“å‡ºæœ€ç»ˆæŠ•èµ„å»ºè®®ã€‚
        ç ”æŠ¥: {report_draft}
        """
        review_res, thinking = call_agent("Chief", SPECIFIC_MODELS["KIMI"], review_prompt, "å¼€å§‹å®¡æ ¸", thinking_needed=True)
        
        if thinking:
            with st.expander("ğŸ§  æ€è€ƒè¿‡ç¨‹", expanded=True):
                st.markdown(f"_{thinking}_")
        
        # Logic for Rework vs Finalize
        if "REWORK:" in review_res and st.session_state.retry_count < 1:
            # REWORK FLOW
            match = re.search(r"REWORK:\s*(\w+)", review_res)
            field = match.group(1).lower() if match else "micro"
            if field not in st.session_state.raw_news: field = "micro"
            
            st.warning(f"ğŸš¨ é©³å›ï¼šè¦æ±‚è¡¥å…… **{field}** é¢†åŸŸä¿¡æ¯ã€‚æ­£åœ¨æ‰§è¡Œ...")
            
            # Supplement Search
            new_query = f"{ticker} {field} deep analysis recent news"
            new_info = search_web(new_query, "general")
            st.session_state.raw_news[field].extend(new_info) # Append Data
            
            st.session_state.retry_count += 1 # Increment Retry
            st.rerun() # Restart analysis with new data
            
        else:
            # SUCCESS FLOW
            st.success("âœ… å®¡æ ¸é€šè¿‡")
            st.markdown(f"### ğŸ† æœ€ç»ˆå†³ç­–\n{review_res}")
            
            # Save final result to history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": f"### ğŸ“‘ æœ€ç»ˆç ”æŠ¥ ({ticker})\n\n{report_draft}\n\n---\n**ğŸ† é¦–å¸­å†³ç­–**: {review_res}", 
                "avatar": "ğŸ‘¨â€ğŸ”¬",
                "thinking": thinking
            })
            st.session_state.process_status = "DONE" # Mark as done
